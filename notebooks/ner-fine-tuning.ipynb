{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nraw_datasets = load_dataset(\"conll2003\")","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:47.669775Z","iopub.execute_input":"2023-01-06T21:58:47.670154Z","iopub.status.idle":"2023-01-06T21:58:48.300112Z","shell.execute_reply.started":"2023-01-06T21:58:47.670123Z","shell.execute_reply":"2023-01-06T21:58:48.299180Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"272a6d3b724341859d9043d395f907df"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:48.301908Z","iopub.execute_input":"2023-01-06T21:58:48.302686Z","iopub.status.idle":"2023-01-06T21:58:48.309124Z","shell.execute_reply.started":"2023-01-06T21:58:48.302648Z","shell.execute_reply":"2023-01-06T21:58:48.308210Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14042\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3251\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3454\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(raw_datasets[\"train\"][\"tokens\"][0])\nprint(raw_datasets[\"train\"][\"ner_tags\"][0])","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:48.310403Z","iopub.execute_input":"2023-01-06T21:58:48.311198Z","iopub.status.idle":"2023-01-06T21:58:48.618235Z","shell.execute_reply.started":"2023-01-06T21:58:48.311147Z","shell.execute_reply":"2023-01-06T21:58:48.617043Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n[3, 0, 7, 0, 0, 0, 7, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_datasets[\"train\"].features[\"ner_tags\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:48.620903Z","iopub.execute_input":"2023-01-06T21:58:48.621344Z","iopub.status.idle":"2023-01-06T21:58:48.628798Z","shell.execute_reply.started":"2023-01-06T21:58:48.621305Z","shell.execute_reply":"2023-01-06T21:58:48.627741Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"},"metadata":{}}]},{"cell_type":"code","source":"label_names = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\nlabel_names","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:48.630087Z","iopub.execute_input":"2023-01-06T21:58:48.631129Z","iopub.status.idle":"2023-01-06T21:58:48.643166Z","shell.execute_reply.started":"2023-01-06T21:58:48.631087Z","shell.execute_reply":"2023-01-06T21:58:48.642049Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}]},{"cell_type":"code","source":"words = raw_datasets[\"train\"][0][\"tokens\"]\nlabels = raw_datasets[\"train\"][0][\"ner_tags\"]\nline1 = \"\"\nline2 = \"\"\nfor word, label in zip(words, labels):\n    full_label = label_names[label]\n    max_length = max(len(word), len(full_label))\n    line1 += word + \" \" * (max_length - len(word) + 1)\n    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\nprint(line1)\nprint(line2)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:48.644302Z","iopub.execute_input":"2023-01-06T21:58:48.645545Z","iopub.status.idle":"2023-01-06T21:58:48.656715Z","shell.execute_reply.started":"2023-01-06T21:58:48.645462Z","shell.execute_reply":"2023-01-06T21:58:48.655678Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"EU    rejects German call to boycott British lamb . \nB-ORG O       B-MISC O    O  O       B-MISC  O    O \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nmodel_checkpoint = \"bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:48.772267Z","iopub.execute_input":"2023-01-06T21:58:48.772534Z","iopub.status.idle":"2023-01-06T21:58:50.336997Z","shell.execute_reply.started":"2023-01-06T21:58:48.772509Z","shell.execute_reply":"2023-01-06T21:58:50.335069Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-cased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 28996\n}\n\nloading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\nloading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\nloading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\nloading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-cased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 28996\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)  # is_split_into_words\nprint(inputs.tokens())\nprint(inputs.word_ids())","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:50.340091Z","iopub.execute_input":"2023-01-06T21:58:50.341413Z","iopub.status.idle":"2023-01-06T21:58:50.357865Z","shell.execute_reply.started":"2023-01-06T21:58:50.341342Z","shell.execute_reply":"2023-01-06T21:58:50.355624Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']\n[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n","output_type":"stream"}]},{"cell_type":"code","source":"def align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]\n            new_labels.append(label)\n        elif word_id is None:\n            new_labels.append(-100)\n        else:\n            label = labels[word_id]\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n    return new_labels","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:50.360030Z","iopub.execute_input":"2023-01-06T21:58:50.360434Z","iopub.status.idle":"2023-01-06T21:58:50.371528Z","shell.execute_reply.started":"2023-01-06T21:58:50.360391Z","shell.execute_reply":"2023-01-06T21:58:50.370901Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"labels = raw_datasets[\"train\"][0][\"ner_tags\"]\nword_ids = inputs.word_ids()\nprint(labels)\nprint(word_ids)\nprint(align_labels_with_tokens(labels, word_ids))","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:50.603679Z","iopub.execute_input":"2023-01-06T21:58:50.604101Z","iopub.status.idle":"2023-01-06T21:58:50.615158Z","shell.execute_reply.started":"2023-01-06T21:58:50.604068Z","shell.execute_reply":"2023-01-06T21:58:50.614126Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"[3, 0, 7, 0, 0, 0, 7, 0, 0]\n[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:50.826715Z","iopub.execute_input":"2023-01-06T21:58:50.827371Z","iopub.status.idle":"2023-01-06T21:58:50.835991Z","shell.execute_reply.started":"2023-01-06T21:58:50.827329Z","shell.execute_reply":"2023-01-06T21:58:50.835056Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"inputs.word_ids()","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:51.032706Z","iopub.execute_input":"2023-01-06T21:58:51.033089Z","iopub.status.idle":"2023-01-06T21:58:51.039986Z","shell.execute_reply.started":"2023-01-06T21:58:51.033054Z","shell.execute_reply":"2023-01-06T21:58:51.038939Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n    for i, labels in enumerate(all_labels):\n        word_ids = tokenized_inputs.word_ids(i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs\n","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:51.255333Z","iopub.execute_input":"2023-01-06T21:58:51.255644Z","iopub.status.idle":"2023-01-06T21:58:51.262169Z","shell.execute_reply.started":"2023-01-06T21:58:51.255618Z","shell.execute_reply":"2023-01-06T21:58:51.261134Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(\n    tokenize_and_align_labels,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:51.437735Z","iopub.execute_input":"2023-01-06T21:58:51.438041Z","iopub.status.idle":"2023-01-06T21:58:54.408570Z","shell.execute_reply.started":"2023-01-06T21:58:51.437988Z","shell.execute_reply":"2023-01-06T21:58:54.407669Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e591f0c52ba423c8245e76eeab3feb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfca53ebe7a04f84b586d20c4da488f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f6c9d758f87409aa6561112c6609813"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:54.410756Z","iopub.execute_input":"2023-01-06T21:58:54.411566Z","iopub.status.idle":"2023-01-06T21:58:54.417985Z","shell.execute_reply.started":"2023-01-06T21:58:54.411521Z","shell.execute_reply":"2023-01-06T21:58:54.417364Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 14042\n    })\n    validation: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 3251\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 3454\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:54.420879Z","iopub.execute_input":"2023-01-06T21:58:54.421555Z","iopub.status.idle":"2023-01-06T21:58:54.440573Z","shell.execute_reply.started":"2023-01-06T21:58:54.421500Z","shell.execute_reply":"2023-01-06T21:58:54.439867Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\nbatch[\"labels\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:54.443299Z","iopub.execute_input":"2023-01-06T21:58:54.443909Z","iopub.status.idle":"2023-01-06T21:58:54.458782Z","shell.execute_reply.started":"2023-01-06T21:58:54.443882Z","shell.execute_reply":"2023-01-06T21:58:54.457882Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(2):\n    print(tokenized_datasets[\"train\"][i][\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:54.461867Z","iopub.execute_input":"2023-01-06T21:58:54.462133Z","iopub.status.idle":"2023-01-06T21:58:54.470162Z","shell.execute_reply.started":"2023-01-06T21:58:54.462109Z","shell.execute_reply":"2023-01-06T21:58:54.468994Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n[-100, 1, 2, -100]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:58:54.472029Z","iopub.execute_input":"2023-01-06T21:58:54.472368Z","iopub.status.idle":"2023-01-06T21:59:03.798439Z","shell.execute_reply.started":"2023-01-06T21:58:54.472334Z","shell.execute_reply":"2023-01-06T21:59:03.797275Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: seqeval in /opt/conda/lib/python3.7/site-packages (1.2.2)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.0.2)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.21.6)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:03.801739Z","iopub.execute_input":"2023-01-06T21:59:03.802663Z","iopub.status.idle":"2023-01-06T21:59:13.278898Z","shell.execute_reply.started":"2023-01-06T21:59:03.802627Z","shell.execute_reply":"2023-01-06T21:59:13.277735Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.7/site-packages (0.4.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.13)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.10.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2022.8.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.13.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (21.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.5.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (5.0.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:13.280686Z","iopub.execute_input":"2023-01-06T21:59:13.282312Z","iopub.status.idle":"2023-01-06T21:59:13.660192Z","shell.execute_reply.started":"2023-01-06T21:59:13.282268Z","shell.execute_reply":"2023-01-06T21:59:13.659260Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"labels = raw_datasets[\"train\"][0][\"ner_tags\"]\nlabels = [label_names[i] for i in labels]\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:13.661495Z","iopub.execute_input":"2023-01-06T21:59:13.661856Z","iopub.status.idle":"2023-01-06T21:59:13.673891Z","shell.execute_reply.started":"2023-01-06T21:59:13.661821Z","shell.execute_reply":"2023-01-06T21:59:13.672937Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"},"metadata":{}}]},{"cell_type":"code","source":"predictions = labels.copy()\npredictions[2] = \"O\"\nmetric.compute(predictions=[predictions], references=[labels])","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:13.675709Z","iopub.execute_input":"2023-01-06T21:59:13.676042Z","iopub.status.idle":"2023-01-06T21:59:13.695336Z","shell.execute_reply.started":"2023-01-06T21:59:13.675991Z","shell.execute_reply":"2023-01-06T21:59:13.694450Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"{'MISC': {'precision': 1.0,\n  'recall': 0.5,\n  'f1': 0.6666666666666666,\n  'number': 2},\n 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 0.6666666666666666,\n 'overall_f1': 0.8,\n 'overall_accuracy': 0.8888888888888888}"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": all_metrics[\"overall_precision\"],\n        \"recall\": all_metrics[\"overall_recall\"],\n        \"f1\": all_metrics[\"overall_f1\"],\n        \"accuracy\": all_metrics[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:13.698119Z","iopub.execute_input":"2023-01-06T21:59:13.698416Z","iopub.status.idle":"2023-01-06T21:59:13.707110Z","shell.execute_reply.started":"2023-01-06T21:59:13.698392Z","shell.execute_reply":"2023-01-06T21:59:13.706074Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"id2label = {i: label for i, label in enumerate(label_names)}\nlabel2id = {v: k for k, v in id2label.items()}","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:13.708538Z","iopub.execute_input":"2023-01-06T21:59:13.708893Z","iopub.status.idle":"2023-01-06T21:59:13.726132Z","shell.execute_reply.started":"2023-01-06T21:59:13.708859Z","shell.execute_reply":"2023-01-06T21:59:13.725181Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:13.730395Z","iopub.execute_input":"2023-01-06T21:59:13.730647Z","iopub.status.idle":"2023-01-06T21:59:15.695201Z","shell.execute_reply.started":"2023-01-06T21:59:13.730623Z","shell.execute_reply":"2023-01-06T21:59:15.694283Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-cased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"O\",\n    \"1\": \"B-PER\",\n    \"2\": \"I-PER\",\n    \"3\": \"B-ORG\",\n    \"4\": \"I-ORG\",\n    \"5\": \"B-LOC\",\n    \"6\": \"I-LOC\",\n    \"7\": \"B-MISC\",\n    \"8\": \"I-MISC\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"B-LOC\": 5,\n    \"B-MISC\": 7,\n    \"B-ORG\": 3,\n    \"B-PER\": 1,\n    \"I-LOC\": 6,\n    \"I-MISC\": 8,\n    \"I-ORG\": 4,\n    \"I-PER\": 2,\n    \"O\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 28996\n}\n\nloading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.num_labels","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:15.699487Z","iopub.execute_input":"2023-01-06T21:59:15.701778Z","iopub.status.idle":"2023-01-06T21:59:15.712076Z","shell.execute_reply.started":"2023-01-06T21:59:15.701740Z","shell.execute_reply":"2023-01-06T21:59:15.711053Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"bert-finetuned-ner\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    push_to_hub=False,\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:15.716703Z","iopub.execute_input":"2023-01-06T21:59:15.717782Z","iopub.status.idle":"2023-01-06T21:59:15.739656Z","shell.execute_reply.started":"2023-01-06T21:59:15.717747Z","shell.execute_reply":"2023-01-06T21:59:15.739064Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-06T21:59:15.740987Z","iopub.execute_input":"2023-01-06T21:59:15.741663Z","iopub.status.idle":"2023-01-06T22:08:43.921189Z","shell.execute_reply.started":"2023-01-06T21:59:15.741626Z","shell.execute_reply":"2023-01-06T22:08:43.919895Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 14042\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 1\n  Total optimization steps = 2634\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2634/2634 09:20, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.212100</td>\n      <td>nan</td>\n      <td>0.913137</td>\n      <td>0.932346</td>\n      <td>0.922641</td>\n      <td>0.982398</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.044900</td>\n      <td>nan</td>\n      <td>0.923506</td>\n      <td>0.946819</td>\n      <td>0.935017</td>\n      <td>0.985092</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.025300</td>\n      <td>nan</td>\n      <td>0.929301</td>\n      <td>0.949007</td>\n      <td>0.939051</td>\n      <td>0.985989</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 3251\n  Batch size = 16\nSaving model checkpoint to bert-finetuned-ner/checkpoint-878\nConfiguration saved in bert-finetuned-ner/checkpoint-878/config.json\nModel weights saved in bert-finetuned-ner/checkpoint-878/pytorch_model.bin\ntokenizer config file saved in bert-finetuned-ner/checkpoint-878/tokenizer_config.json\nSpecial tokens file saved in bert-finetuned-ner/checkpoint-878/special_tokens_map.json\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 3251\n  Batch size = 16\nSaving model checkpoint to bert-finetuned-ner/checkpoint-1756\nConfiguration saved in bert-finetuned-ner/checkpoint-1756/config.json\nModel weights saved in bert-finetuned-ner/checkpoint-1756/pytorch_model.bin\ntokenizer config file saved in bert-finetuned-ner/checkpoint-1756/tokenizer_config.json\nSpecial tokens file saved in bert-finetuned-ner/checkpoint-1756/special_tokens_map.json\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 3251\n  Batch size = 16\nSaving model checkpoint to bert-finetuned-ner/checkpoint-2634\nConfiguration saved in bert-finetuned-ner/checkpoint-2634/config.json\nModel weights saved in bert-finetuned-ner/checkpoint-2634/pytorch_model.bin\ntokenizer config file saved in bert-finetuned-ner/checkpoint-2634/tokenizer_config.json\nSpecial tokens file saved in bert-finetuned-ner/checkpoint-2634/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2634, training_loss=0.07548761195817859, metrics={'train_runtime': 567.9412, 'train_samples_per_second': 74.173, 'train_steps_per_second': 4.638, 'total_flos': 1049600569014468.0, 'train_loss': 0.07548761195817859, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}